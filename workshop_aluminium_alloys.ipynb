{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"alloy_data.xlsx\"\n",
    "\n",
    "df = pd.read_excel(datafile, skiprows=1)\n",
    "print(f\"The dataframe has {df.shape[1]} columns and {df.shape[0]} rows\")\n",
    "print(list(df.columns))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve the columns for chemical composition\n",
    "composition_cols = [col for col in df.columns if \"%\" in col]\n",
    "composition_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input variables for the model in the paper are the chemical composition and the temper\n",
    "paper_x_cols = composition_cols + [\"temper\"]\n",
    "print(paper_x_cols)\n",
    "\n",
    "# cases = [\"No Temper\", \"Temper\", \"Truncated\", \"Numerical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data: pd.DataFrame, x_cols: List[str], y_col: str, random_state: int = 1234, validator: str = \"loocv\"):\n",
    "    \"\"\"Provide out-of-sample cross validation for a dataset\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): model data\n",
    "        x_cols (List[str]): input columns for the model\n",
    "        y_col (str): predicted variable\n",
    "        random_state (int, optional): random initializer. Defaults to 1234.\n",
    "        validator (str, optional): validation strategy. Defaults to \"loocv\".\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray]: (y_true, y_pred)\n",
    "    \"\"\"\n",
    "    VALIDATORS = {\n",
    "        \"loocv\": LeaveOneOut(),\n",
    "        \"5foldcv\": KFold(n_splits=5),\n",
    "        \"15foldcv\": KFold(n_splits=15),\n",
    "        \"20foldcv\": KFold(n_splits=20),\n",
    "    }\n",
    "\n",
    "    random_forest = RandomForestRegressor(random_state=random_state)\n",
    "    \n",
    "    # Use get_dummies to convert categorical data to numerical columns (one-hot encoding)\n",
    "    model_input = pd.get_dummies(data.loc[:, x_cols])\n",
    "    \n",
    "    # For in-sample validation, train and predict on the entire set at once\n",
    "    if validator==\"insample\":\n",
    "        y_true = data.loc[:, y_col]\n",
    "        random_forest.fit(model_input, y_true)\n",
    "        y_pred = random_forest.predict(model_input)\n",
    "        return y_true, y_pred\n",
    "\n",
    "    \n",
    "    # For cross validation, use the appropriate validator\n",
    "    validator = VALIDATORS[validator]\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for train_index, test_index in tqdm(validator.split(model_input)):\n",
    "        y_true.append(data.loc[test_index, y_col])\n",
    "\n",
    "        random_forest.fit(model_input.loc[train_index, :], data.loc[train_index, y_col])\n",
    "        y_pred.append(random_forest.predict(model_input.loc[test_index]))\n",
    "    \n",
    "    return np.concatenate(y_true), np.concatenate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_r2_plot(data: pd.DataFrame, x_cols: List[str], y_col: str, random_state: int = 1234, validator: str = \"loocv\"):\n",
    "    \"\"\"Make a plot of R2 data using different CV strategies.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): model data\n",
    "        x_cols (List[str]): input columns for the model\n",
    "        y_col (str): predicted variable\n",
    "        random_state (int, optional): random initializer. Defaults to 1234.\n",
    "        validator (str, optional): validation strategy. Defaults to \"loocv\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    y_true, y_pred = cross_validation(data, x_cols, y_col, random_state=random_state, validator=validator)\n",
    "\n",
    "    r2 = r2_score(y_pred=y_pred, y_true=y_true)\n",
    "\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    ax.scatter(y_true, y_pred)\n",
    "\n",
    "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], c=\"k\", linestyle=\"--\")\n",
    "\n",
    "    ax.annotate(rf\"$R^2 = {{{r2:.2f}}}$\", xy=(.1, .9), xycoords=\"axes fraction\")\n",
    "    ax.set_aspect(1.)\n",
    "    ax.set_xlabel(f\"Experimental {y_col}\")\n",
    "    ax.set_ylabel(f\"Predicted {y_col}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variable_importance_plot(data: pd.DataFrame, x_cols: List[str], y_col: str, random_state: int = 1234):\n",
    "    \"\"\"Make a plot of the variable importance for different models.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): model data\n",
    "        x_cols (List[str]): input columns for the model\n",
    "        y_col (str): predicted variable\n",
    "        random_state (int, optional): random initializer. Defaults to 1234.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    random_forest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "    model_input = pd.get_dummies(data.loc[:, x_cols])\n",
    "    model_xcols = model_input.columns\n",
    "    \n",
    "    random_forest.fit(model_input, data.loc[:, y_col])\n",
    "\n",
    "\n",
    "    importances = random_forest.feature_importances_\n",
    "    std_importances = np.std([tree.feature_importances_ for tree in random_forest.estimators_], axis=0)\n",
    "    std_importances = pd.Series(std_importances)\n",
    "    top_std = np.array(std_importances.nlargest(10))\n",
    "    feat_importances = pd.Series(importances, index=model_xcols)\n",
    "    topfeatures = feat_importances.nlargest(10)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,8))\n",
    "    \n",
    "    colors = [\"steelblue\" if \"temper\" not in col else \"darkred\" for col in topfeatures.index]\n",
    "\n",
    "    topfeatures.plot.bar(yerr = top_std ,ax=ax, color = colors)\n",
    "\n",
    "    ax.set_ylabel('Feature importance')\n",
    "\n",
    "\n",
    "    fig.text(0.8, 0.8, y_col, color='black', ha='center')\n",
    "\n",
    "    plt.xticks(rotation=55)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.ylim((0,0.7))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a column to predict\n",
    "y_col = \"TYS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_r2_plot(df, paper_x_cols, y_col=y_col, validator=\"loocv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_variable_importance_plot(df, paper_x_cols, y_col=y_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "- Make the same plots for the other mechanical properties by changing the value of `y_col`. Do the plots resemble those in the paper?\n",
    "    - If you need hints for the possible values of `y_col`, look at the output of the second cell.\n",
    "- What happens to the R2 plot if you change the validator to `validator=\"insample\"`? Can you explain why this happens?\n",
    "- What happens to the R2 plot if you change validation strategies to `validator=\"5foldcv\"`? What if you change to `\"15foldcv\"`?\n",
    "- Which variables are more sensitive to these changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your own answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it easier to compare the different validation strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_R2s(data: pd.DataFrame, x_cols: List[str], y_col: str):\n",
    "    \"\"\"Calculate the R2 value for four different CV strategies\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): model data\n",
    "        x_cols (List[str]): input columns for the model\n",
    "        y_col (str): predicted variable\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of strategies and R2 values\n",
    "    \"\"\"\n",
    "    r2_values = {}\n",
    "\n",
    "    validators = {\n",
    "        \"insample\": \"In Sample\",\n",
    "        \"loocv\": \"Leave One Out CV\",\n",
    "        \"5foldcv\": \"5 Fold CV\",\n",
    "        \"15foldcv\": \"15 Fold CV\",\n",
    "        \"20foldcv\": \"20 Fold CV\",\n",
    "    }\n",
    "    for validator, name in validators.items():\n",
    "        y_true_in_sample, y_pred_in_sample = cross_validation(data, x_cols, y_col, validator=validator)\n",
    "        r2_value = r2_score(y_pred=y_pred_in_sample, y_true=y_true_in_sample)\n",
    "        r2_values.update({name: r2_value})\n",
    "\n",
    "    return r2_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"TYS\"\n",
    "paper_r2s = calc_R2s(df, paper_x_cols, y_col=y_col)\n",
    "pd.DataFrame({\"Paper\": paper_r2s}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not generalize that well with even a small out-of-sample validation set.\n",
    "Let's have a look at the distribution of tempers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temper_counts = (\n",
    "    df[[\"alloy name\", \"temper\"]]\n",
    "    .groupby(\"temper\")\n",
    "    .count()\n",
    "    .rename(columns={\"alloy name\": \"count\"})\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "temper_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And make a plot of the size distribution\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.hist(temper_counts, bins=28, align=\"left\")\n",
    "ax.set_xlabel(\"Temper group size\")\n",
    "ax.set_ylabel(\"Frequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 0\n",
    "\n",
    "max_count = 3\n",
    "\n",
    "for i in range(1, max_count+1):\n",
    "    rows += i*temper_counts[temper_counts[\"count\"]==i].shape[0]\n",
    "\n",
    "print(f\"{rows/temper_counts['count'].sum()* 100:.1f} % of all rows belongs to a temper with 3 or fewer rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than a quarter of all rows belong to a temper with 3 or fewer rows. So many small categories make it difficult to generalize the model.\n",
    "\n",
    "A lot of the low-frequency tempers have more than 1 digit. What happens if we truncate the temper after the first digit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate temper column to two characters, e.g. T614 --> T6\n",
    "# N.B., O only has a single character\n",
    "# Create a list of columns for a new model\n",
    "\n",
    "df[\"temper_truncated\"] = df[\"temper\"].apply(lambda x: x[:2] if x != \"O\" else x)\n",
    "trunc_x_cols = composition_cols + [\"temper_truncated\"]\n",
    "print(trunc_x_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have another look at the size distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_temper_counts = (\n",
    "    df[[\"alloy name\", \"temper_truncated\"]]\n",
    "    .groupby(\"temper_truncated\")\n",
    "    .count()\n",
    "    .rename(columns={\"alloy name\": \"count\"})\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "truncated_temper_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has fewer groups, and the groups have a larger size. Hopefully the model generalizes better with this input.\n",
    "\n",
    "Let's check this by making the plots and table that we have done previously, but instead of `\"temper\"` we use `\"temper_truncated\"` as an input column.\n",
    "We do that by using `x_cols=trunc_x_cols` in the function call:\n",
    "\n",
    "```python\n",
    "y_col = ...\n",
    "make_r2_plot(df, x_cols=trunc_x_cols, y_col=y_col, validator=\"loocv\")\n",
    "\n",
    "make_variable_importance_plot(df, trunc_x_cols, y_col=y_col)\n",
    "\n",
    "paper_r2s = calc_R2s(df, trunc_x_cols, y_col=y_col)\n",
    "pd.DataFrame({\"Paper\": paper_r2s}).T\n",
    "```\n",
    "\n",
    "## Exercise\n",
    "\n",
    "- Make the same plots as before, but now with the truncated temper.\n",
    "- Play with the different validation strategies and see what happens to the R2.\n",
    "    - How do the R2 values compare to the ones in the paper?\n",
    "    - And to the ones in the previous exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your exercise answers\n",
    "make_r2_plot(df, trunc_x_cols, y_col=y_col, validator=\"20foldcv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It already does a lot better than before.\n",
    "However, there is still some room for improvement.\n",
    "For example, temper T9 only has a single row, but T8 has 18 rows.\n",
    "What happens if we do the following:\n",
    "- use the temper letter (H, T, O) as a categorical variable?\n",
    "- use the first temper number as numerical variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the temper into two columns, the letter and the first digit\n",
    "# NB: temper O has no number, so we assign it the number 1\n",
    "df[\"temper_c0\"] = df['temper'].apply(lambda x: x[0])\n",
    "df[\"temper_c1\"] = df['temper'].apply(lambda x: int(x[1]) if len(x)>1 else 1)\n",
    "\n",
    "# Provide a new list of x columns\n",
    "split_x_cols = composition_cols + [\"temper_c0\", \"temper_c1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we are justified in doing this with a simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(data=df, x=\"temper_c1\", y=y_col, hue=\"temper_c0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "- Make the same plots as before, but now with the split temper columns (`x_cols=split_x_cols`).\n",
    "- Play with the different validation strategies and see what happens to the R2.\n",
    "    - How do the R2 values compare to the ones in the paper?\n",
    "    - And to the ones in the previous exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_r2_plot(df, x_cols=split_x_cols, y_col=y_col, validator=\"loocv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One final overview\n",
    "\n",
    "As a final overview, let's have a look at the R2 scores for the different ways of using temper and the different cross validation strategies.\n",
    "Are there conclusions you can draw about the different ways of treating temper and the different CV strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = {}\n",
    "\n",
    "cases = [\"No Temper\", \"Temper\", \"Truncated\", \"Split\"]\n",
    "for case, x_cols in zip(cases, [composition_cols, paper_x_cols, trunc_x_cols, split_x_cols]):\n",
    "    print(f\"Working on {case}\")\n",
    "    model_scores.update({case: calc_R2s(df, x_cols=x_cols, y_col=y_col)})\n",
    "\n",
    "msdf = pd.DataFrame(model_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msdf.apply(round, args=(3,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
